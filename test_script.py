{
 "metadata": {
  "name": "",
  "signature": "sha256:b7eeda1657916d22c43b1385f9a89407c7d3102e100a35d651a78ed20951da54"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn.svm import SVC\n",
      "# from sklearn.ensemble import RandomForestClassifier\n",
      "# from sklearn.calibration import CalibratedClassifierCV\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn import metrics\n",
      "\n",
      "from sklearn.pipeline import Pipeline,FeatureUnion\n",
      "from sklearn import grid_search\n",
      "\n",
      "import distance\n",
      "\n",
      "\n",
      "# The following 3 functions have been taken from Ben Hamner's github repository\n",
      "# https://github.com/benhamner/Metrics\n",
      "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
      "    \"\"\"\n",
      "    Returns the confusion matrix between rater's ratings\n",
      "    \"\"\"\n",
      "    assert(len(rater_a) == len(rater_b))\n",
      "    if min_rating is None:\n",
      "        min_rating = min(rater_a + rater_b)\n",
      "    if max_rating is None:\n",
      "        max_rating = max(rater_a + rater_b)\n",
      "    num_ratings = int(max_rating - min_rating + 1)\n",
      "    conf_mat = [[0 for i in range(num_ratings)]\n",
      "                for j in range(num_ratings)]\n",
      "    for a, b in zip(rater_a, rater_b):\n",
      "        conf_mat[a - min_rating][b - min_rating] += 1\n",
      "    return conf_mat\n",
      "\n",
      "\n",
      "def histogram(ratings, min_rating=None, max_rating=None):\n",
      "    \"\"\"\n",
      "    Returns the counts of each type of rating that a rater made\n",
      "    \"\"\"\n",
      "    if min_rating is None:\n",
      "        min_rating = min(ratings)\n",
      "    if max_rating is None:\n",
      "        max_rating = max(ratings)\n",
      "    num_ratings = int(max_rating - min_rating + 1)\n",
      "    hist_ratings = [0 for x in range(num_ratings)]\n",
      "    for r in ratings:\n",
      "        hist_ratings[r - min_rating] += 1\n",
      "    return hist_ratings\n",
      "\n",
      "\n",
      "def quadratic_weighted_kappa(y, y_pred):\n",
      "    \"\"\"\n",
      "    Calculates the quadratic weighted kappa\n",
      "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
      "    value, which is a measure of inter-rater agreement between two raters\n",
      "    that provide discrete numeric ratings.  Potential values range from -1\n",
      "    (representing complete disagreement) to 1 (representing complete\n",
      "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
      "    chance.\n",
      "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
      "    each correspond to a list of integer ratings.  These lists must have the\n",
      "    same length.\n",
      "    The ratings should be integers, and it is assumed that they contain\n",
      "    the complete range of possible ratings.\n",
      "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
      "    is the minimum possible rating, and max_rating is the maximum possible\n",
      "    rating\n",
      "    \"\"\"\n",
      "    rater_a = y\n",
      "    rater_b = y_pred\n",
      "    min_rating=None\n",
      "    max_rating=None\n",
      "    rater_a = np.array(rater_a, dtype=int)\n",
      "    rater_b = np.array(rater_b, dtype=int)\n",
      "    assert(len(rater_a) == len(rater_b))\n",
      "    if min_rating is None:\n",
      "        min_rating = min(min(rater_a), min(rater_b))\n",
      "    if max_rating is None:\n",
      "        max_rating = max(max(rater_a), max(rater_b))\n",
      "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
      "                                min_rating, max_rating)\n",
      "    num_ratings = len(conf_mat)\n",
      "    num_scored_items = float(len(rater_a))\n",
      "\n",
      "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
      "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
      "\n",
      "    numerator = 0.0\n",
      "    denominator = 0.0\n",
      "\n",
      "    for i in range(num_ratings):\n",
      "        for j in range(num_ratings):\n",
      "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
      "                              / num_scored_items)\n",
      "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
      "            numerator += d * conf_mat[i][j] / num_scored_items\n",
      "            denominator += d * expected_count / num_scored_items\n",
      "\n",
      "    return (1.0 - numerator / denominator)\n",
      "\n",
      "\n",
      "def load_train(path,svd_n = 140):\n",
      "    train = pd.read_csv(path)\n",
      "    y = train.median_relevance.values    \n",
      "    train = train.drop(['id','median_relevance','median_relevance'], axis = 1)\n",
      "    \n",
      "    train_processed = do_cleaning_and_combined(train)\n",
      "    \n",
      "    tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
      "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
      "        ngram_range=(1,2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
      "        stop_words = 'english')\n",
      "    \n",
      "    X_train = tfv.fit_transform(train_processed)\n",
      "    \n",
      "    # LSA / SVD\n",
      "    svd = None\n",
      "    if svd_n > 0:\n",
      "        svd = TruncatedSVD(n_components = svd_n) #n_components = 140\n",
      "        X_train = svd.fit_transform(X_train)\n",
      "    return train,X_train,y,tfv,svd\n",
      "    \n",
      "def load_test(path,tfv,svd):\n",
      "    test = pd.read_csv(path)\n",
      "    idx = test.id.values\n",
      "    test = test.drop(['id'], axis=1)\n",
      "    \n",
      "    test_processed = do_cleaning_and_combined(test)\n",
      "    X_test = tfv.transform(test_processed)\n",
      "    \n",
      "    if svd != None:\n",
      "        X_test = svd.transform(X_test)\n",
      "    \n",
      "    return test,X_test,idx\n",
      "\n",
      "def do_cleaning_and_combined(data):\n",
      "    processed = list(data.apply(lambda x:'%s %s %s' % (x['query'],x['product_title'], x['product_description']),axis=1))\n",
      "    return processed\n",
      "\n",
      "def feature_extraction(df):\n",
      "    \n",
      "    stop_words = [\"a\" , \"about\" , \"above\" , \"after\" , \"again\" , \"against\" , \"all\" , \"am\" , \"an\" , \"and\" , \"any\" , \"are\" , \n",
      "              \"aren't\" , \"as\" , \"at\" , \"be\" , \"because\" , \"been\" , \"before\" , \"being\" , \"below\" , \"between\" , \"both\" ,\n",
      "              \"but\" , \"by\" , \"can't\" , \"cannot\" , \"could\" , \"couldn't\" , \"did\" , \"didn't\" , \"do\" , \"does\" , \"doesn't\" , \n",
      "              \"doing\" , \"don't\" , \"down\" , \"during\" , \"each\" , \"few\" , \"for\" , \"from\" , \"further\" , \"had\" , \"hadn't\" , \n",
      "              \"has\" , \"hasn't\" , \"have\" , \"haven't\" , \"having\" , \"he\" , \"he'd\" , \"he'll\" , \"he's\" , \"her\" , \"here\" , \n",
      "              \"here's\" , \"hers\" , \"herself\" , \"him\" , \"himself\" , \"his\" , \"how\" , \"how's\" , \"i\" , \"i'd\" , \"i'll\" , \"i'm\" ,\n",
      "              \"i've\" , \"if\" , \"in\" , \"into\" , \"is\" , \"isn't\" , \"it\" , \"it's\" , \"its\" , \"itself\" , \"let's\" , \"me\" , \"more\" , \n",
      "              \"most\" , \"mustn't\" , \"my\" , \"myself\" , \"no\" , \"nor\" , \"not\" , \"of\" , \"off\" , \"on\" , \"once\" , \"only\" , \"or\" ,\n",
      "              \"other\" , \"ought\" , \"our\" , \"ours\"]\n",
      "    \n",
      "    #lower case\n",
      "    \n",
      "    df_columns = df.columns\n",
      "    df.query = df['query'].str.lower()\n",
      "    df.product_title = df.product_title.str.lower()\n",
      "    df.product_description = df.product_description.str.lower()\n",
      "    \n",
      "    # remove punchuations\n",
      "    df.query = df['query'].str.replace('[^a-zA-Z0-9\\s]', '', case=False)\n",
      "    df.product_title = df.product_title.str.replace('[^a-zA-Z0-9\\s]', '', case=False)\n",
      "    df.product_description = df.product_description.str.replace('[^a-zA-Z0-9\\s]', '', case=False)\n",
      "    \n",
      "    #remove new line characters\n",
      "    df.product_description = df.product_description.str.replace('\\n', ' ', case=False)\n",
      "    \n",
      "    #removing 'es' or 's' at the end of the words\n",
      "    df.query = df['query'].str.replace('es\\\\b|s\\\\b', '', case=False)\n",
      "    df.product_title = df.product_title.str.replace('es\\\\b|s\\\\b', '', case=False)\n",
      "    df.product_description = df.product_description.str.replace('es\\\\b|s\\\\b', '', case=False)\n",
      "    \n",
      "    #remove colors\n",
      "    df.product_title = df.product_title.str.replace('red|blue|pink|black|yellow', '', case=False)\n",
      "    \n",
      "    df['query_length'] = df.apply(lambda x : len(x.query.split()), axis = 1)\n",
      "    df['title_length'] = df.apply(lambda x : len(x.product_title.split()), axis = 1)\n",
      "    df['desc_length'] = df.apply(lambda x : len(str(x.product_description).split()), axis = 1)\n",
      "    \n",
      "#     df['desc_length_log'] = np.log(df['desc_length'])\n",
      "    \n",
      "    df['query_title_matched_words'] = df.apply(lambda x: len(set(x.query.split()).intersection(set(x.product_title.split()))), axis = 1)\n",
      "    \n",
      "    df['jacard_dist'] = df.apply(lambda x: distance.jaccard(x.query,x.product_title), axis = 1)\n",
      "    df['jacard_dist_words'] = df.apply(lambda x: distance.jaccard(x.query.split(),x.product_title.split()), axis = 1)\n",
      "    \n",
      "    df['query_1st_word_in_title'] = df.apply(lambda x: x.product_title.split().count(x.query.split()[0]), axis = 1)\n",
      "    \n",
      "    print df.shape\n",
      "    df = df.drop(df_columns,axis = 1)\n",
      "    return df\n",
      "\n",
      "\n",
      "\n",
      "train,X_train,y,tfv,svd = load_train(path=\"data/train.csv\",svd_n = 200)\n",
      "test,X_test,idx = load_test(\"data/test.csv\",tfv,svd)\n",
      "\n",
      "# print 'X_train shape',X_train.shape\n",
      "train_features = feature_extraction(train)\n",
      "test_features = feature_extraction(test)\n",
      "\n",
      "# print 'Extracted features shape',train_features.shape\n",
      "\n",
      "X_train = np.hstack((X_train, train_features.values))\n",
      "X_test = np.hstack((X_test, test_features.values))\n",
      "\n",
      "    \n",
      "# Initialize SVD\n",
      "# svd = TruncatedSVD()\n",
      "    \n",
      "# Initialize the standard scaler \n",
      "scl = StandardScaler()\n",
      "    \n",
      "# We will use SVM here..\n",
      "svm_model = SVC()\n",
      "    \n",
      "# Create the pipeline \n",
      "\n",
      "clf = Pipeline([#('svd', svd),\n",
      "                         ('scl', scl),\n",
      "                         ('svm', svm_model)])\n",
      "    \n",
      "# Create a parameter grid to search for best parameters for everything in the pipeline\n",
      "param_grid = {#'svd__n_components' : [100,150,200,250,300,350,400],\n",
      "                  'svm__C': [1,10,100,1000,1.e4,1.e5]}\n",
      "    \n",
      "# Kappa Scorer \n",
      "kappa_scorer = metrics.make_scorer(quadratic_weighted_kappa, greater_is_better = True)\n",
      "    \n",
      "# Initialize Grid Search Model\n",
      "model = grid_search.GridSearchCV(estimator = clf, param_grid=param_grid, scoring=kappa_scorer,\n",
      "                                     verbose=10, n_jobs=-1, iid=True, refit=True, cv=4)\n",
      "                                     \n",
      "# Fit Grid Search Model\n",
      "model.fit(X_train, y)\n",
      "print(\"Best score: %0.3f\" % model.best_score_)\n",
      "print(\"Best parameters set:\")\n",
      "best_parameters = model.best_estimator_.get_params()\n",
      "for param_name in sorted(param_grid.keys()):\n",
      "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
      "    \n",
      "# Get best model\n",
      "best_model = model.best_estimator_\n",
      "    \n",
      "# Fit best SVM Model\n",
      "best_model.fit(X_train, y)\n",
      "preds = best_model.predict(X_test)\n",
      "\n",
      "# Create submission file\n",
      "submission = pd.DataFrame({\"id\": idx, \"prediction\": preds})\n",
      "submission.to_csv(\"predictions/SVC_with_features_1.csv\", index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(10158, 11)\n",
        "(22513, 10)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:  1.0min\n",
        "[Parallel(n_jobs=-1)]: Done   2 jobs       | elapsed:  1.1min\n",
        "[Parallel(n_jobs=-1)]: Done   8 jobs       | elapsed:  2.1min\n",
        "[Parallel(n_jobs=-1)]: Done   5 jobs       | elapsed:  2.1min\n",
        "[Parallel(n_jobs=-1)]: Done  13 jobs       | elapsed:  4.9min\n",
        "[Parallel(n_jobs=-1)]: Done  18 out of  24 | elapsed:  6.1min remaining:  2.0min\n",
        "[Parallel(n_jobs=-1)]: Done  21 out of  24 | elapsed:  7.2min remaining:  1.0min\n",
        "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  7.4min finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best score: 0.610\n",
        "Best parameters set:\n",
        "\tsvm__C: 10\n",
        "[CV] svm__C=1 ........................................................\n",
        "[CV] svm__C=1 ........................................................\n",
        "[CV] svm__C=1 ........................................................\n",
        "[CV] svm__C=1 ........................................................\n",
        "[CV] ............................... svm__C=1, score=0.478206 - 1.0min[CV] ............................... svm__C=1, score=0.465446 - 1.0min[CV] ............................... svm__C=1, score=0.468307 - 1.0min[CV] ............................... svm__C=1, score=0.476433 - 1.0min\n",
        "\n",
        "\n",
        "\n",
        "[CV] svm__C=10 .......................................................[CV] svm__C=10 .......................................................[CV] svm__C=10 .......................................................[CV] svm__C=10 .......................................................\n",
        "\n",
        "\n",
        "\n",
        "[CV] .............................. svm__C=10, score=0.603772 - 1.1min[CV] .............................. svm__C=10, score=0.609155 - 1.1min[CV] .............................. svm__C=10, score=0.617301 - 1.1min[CV] .............................. svm__C=10, score=0.611615 - 1.0min\n",
        "\n",
        "\n",
        "\n",
        "[CV] svm__C=100 ......................................................[CV] svm__C=100 ......................................................[CV] svm__C=100 ......................................................[CV] svm__C=100 ......................................................\n",
        "\n",
        "\n",
        "\n",
        "[CV] ............................. svm__C=100, score=0.577858 - 1.4min[CV] ............................. svm__C=100, score=0.560599 - 1.4min[CV] ............................. svm__C=100, score=0.582977 - 1.3min[CV] ............................. svm__C=100, score=0.572438 - 1.4min\n",
        "\n",
        "\n",
        "\n",
        "[CV] svm__C=1000 .....................................................[CV] svm__C=1000 .....................................................[CV] svm__C=1000 .....................................................[CV] svm__C=1000 .....................................................\n",
        "\n",
        "\n",
        "\n",
        "[CV] ............................ svm__C=1000, score=0.562418 - 1.2min[CV] ............................ svm__C=1000, score=0.571774 - 1.2min[CV] ............................ svm__C=1000, score=0.559625 - 1.4min[CV] ............................ svm__C=1000, score=0.559623 - 1.4min\n",
        "\n",
        "\n",
        "\n",
        "[CV] svm__C=10000.0 ..................................................[CV] svm__C=10000.0 ..................................................[CV] svm__C=10000.0 ..................................................[CV] svm__C=10000.0 ..................................................\n",
        "\n",
        "\n",
        "\n",
        "[CV] ......................... svm__C=10000.0, score=0.559975 - 1.2min[CV] ......................... svm__C=10000.0, score=0.560823 - 1.2min[CV] ......................... svm__C=10000.0, score=0.570717 - 1.3min[CV] ......................... svm__C=10000.0, score=0.551864 - 1.3min\n",
        "\n",
        "\n",
        "\n",
        "[CV] svm__C=100000.0 .................................................[CV] svm__C=100000.0 .................................................[CV] svm__C=100000.0 .................................................[CV] svm__C=100000.0 .................................................\n",
        "\n",
        "\n",
        "\n",
        "[CV] ........................ svm__C=100000.0, score=0.549246 - 1.3min[CV] ........................ svm__C=100000.0, score=0.554119 - 1.2min[CV] ........................ svm__C=100000.0, score=0.549367 - 1.2min[CV] ........................ svm__C=100000.0, score=0.533971 - 1.2min\n",
        "\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## LB Score : 0.61324"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
